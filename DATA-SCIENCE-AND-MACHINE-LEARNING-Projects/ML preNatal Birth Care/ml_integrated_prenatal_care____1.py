# -*- coding: utf-8 -*-
"""ML_Integrated PreNatal Care.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17TY4Qosz6el7jjBQAG2XhNQ_GOZE2X9R

# **Integrated PreNATAL Care**

*ML Course Project*

1.   Mohammad Sufyan Azam
2.   Aamleen Ahmed
3.   Mohammad Shariq
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive
# %cd ML_Project

"""# Importing Libraries and Dataset"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('fetal_CTG_dataset.csv')
df

df.info()

"""# PreProcessing Data

## Outliers & Null_Values & Other Analysis



1.   Checking Null Value
2.   Handling Columns
3.   Handling Outliers

#### Printing Dataset Headers
"""

i = 1
for name in list(df.columns):
    print(f'{i}.', name)
    i += 1

"""#### Checking and Removing Null Values"""

# Checking for null values
df.isna().sum(axis=0)

# Removing null value rows
df = df.dropna(how='any',axis=0)
df

# Dropping FileName, Date and SegFile
df = df.drop(df.columns[[0, 1, 2]], axis=1)
df

i = 1
for name in list(df.columns):
    print(f'{i}.', name)
    i += 1

"""#### Changing Coloumn Headers"""

new_col_names = {
"b": "start_instant",
"e": "end_instant",
"LBE": "baseline_value_expert",
"LB": "baseline_value_SisPorto",
"AC": "accelerations_SisPorto",
"FM": "foetal_movement_SisPorto",
"UC": "uterine_contractions_SisPorto",
"ASTV": "abnormal_short_term_var_SisPorto",
"MSTV": "mean_short_term_var_SisPorto",
"ALTV": "abnormal_long_term_var_SisPorto",
"MLTV": "mean_long_term_var_SisPorto",
"DL": "light_decelerations",
"DS": "severe_decelerations",
"DP": "prolongued_decelerations",
"DR": "repetitive_decelerations",
"Width": "histogram_width",
"Min": "low_freq_histogram",
"Max": "high_freq_histogram",
"Nmax": "total_histogram_peaks",
"Nzeros": "total_histogram_zeros",
"Mode": "histogram_mode",
"Mean": "histogram_mean",
"Median": "histogram_median",
"Variance": "histogram_variance",
"Tendency": "histogram_tendency",
"A": "calm_sleep",
"B": "REM_sleep",
"C": "calm_vigilance",
"D": "active_vigilance",
"E": "E",
"SH": "shift_pattern",
"AD": "accel/decel_pattern_stress",
"DE": "decelerative_pattern_vagal",
"LD": "large_decelerative_pattern",
"FS": "flat_sinusoidal_pattern",
"SUSP": "suspect_pattern",
"CLASS": "class_code",
"NSP": "Output"
}
df = df.rename(columns = new_col_names)
df

"""## Checking and removing outliers

#### Box plot for checking outliers
"""

fig, ax = plt.subplots(1, 1, figsize=(20, 20))
box1 = df.drop(['start_instant',	'end_instant', 'Output'], axis=1)
box1.boxplot(ax=ax, rot=90, showfliers=True)
plt.tight_layout()
plt.show()

# threshold = {
# "accelerations_SisPorto": 3,
# "foetal_movement_SisPorto": 2,
# "uterine_contractions_SisPorto": 3,
# "mean_short_term_var_SisPorto": 2,
# "abnormal_long_term_var_SisPorto": ,
# "mean_long_term_var_SisPorto": ,
# "light_decelerations": ,
# "severe_decelerations": ,
# "prolongued_decelerations": ,
# "high_freq_histogram": ,
# "total_histogram_peaks": ,
# "total_histogram_zeros": ,
# "histogram_mode": ,
# "histogram_mean": ,
# "histogram_median": ,
# "histogram_variance": ,
# "histogram_tendency": ,
# "calm_sleep": ,
# "REM_sleep": ,
# "calm_vigilance": ,
# "active_vigilance": ,
# "E": ,
# "accel/decel_pattern_stress": ,
# "decelerative_pattern_vagal": ,
# "large_decelerative_pattern": ,
# "flat_sinusoidal_pattern": ,
# "suspect_pattern": ,
# }


# Box plots for first two colummns
fig, ax = plt.subplots(1, 1, figsize=(20, 20))
box2 = df[['start_instant', 'end_instant']]
box2.boxplot(ax=ax, rot=90, showfliers=True)
plt.tight_layout()
plt.show()

"""#### Z-Score"""

# Removing outliers present in the data using z-score
from scipy import stats
df_outlier_z = df.copy(deep=True)
for col in df.columns:
    z_scores = np.abs(stats.zscore(df[col]))
    df_outlier_z[col] = df[col][(z_scores < 3)]
df_outlier_z

df_outlier_z.isnull().sum(axis=0)
df_outlier_z = df_outlier_z.drop(["repetitive_decelerations"], axis=1)
df_outlier_z = df_outlier_z.dropna(how='any',axis=0)
df_outlier_z

fig, ax = plt.subplots(1, 1, figsize=(20, 20))
box3 = df_outlier_z.drop(['start_instant', 'end_instant', 'baseline_value_expert', 'baseline_value_SisPorto', 'Output'], axis=1)
box3.boxplot(ax=ax, rot=90, showfliers=True)
plt.tight_layout()
plt.show()

"""#### KNN Imputer"""

# Removing Outliers Present in the Data using substitution method - KNN Imputer
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)
df_outlier_z_knn = pd.DataFrame(imputer.fit_transform(df_outlier_z), columns = df_outlier_z.columns)
df_outlier_z_knn

print(df_outlier_z_knn.isnull().sum(axis=0))
fig, ax = plt.subplots(1, 1, figsize=(20, 20))
box6 = df_outlier_z_knn.drop(['start_instant', 'end_instant', 'baseline_value_expert', 'baseline_value_SisPorto', 'Output'], axis=1)
box6.boxplot(ax=ax, rot=90, showfliers=True)
plt.tight_layout()
plt.show()

"""#### Inter Quartile Range"""

# # Removing outliers present in the data using IQR
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
# print(IQR)
df_outlier_iqr = df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]
df_outlier_iqr

# df_outlier_iqr.isnull().sum(axis=0)
fig, ax = plt.subplots(1, 1, figsize=(20, 20))
box4 = df_outlier_iqr.drop(['start_instant', 'end_instant', 'baseline_value_expert', 'baseline_value_SisPorto', 'Output'], axis=1)
box4.boxplot(ax=ax, rot=90, showfliers=True)
plt.tight_layout()
plt.show()

"""#### Robust Covariance"""

# Removing outliers present in the data using Robust Covariance
from sklearn.covariance import EllipticEnvelope
clf = EllipticEnvelope(random_state=0).fit(df)
# clf.predict(df)
df_outlier_robust_covariance = df[clf.predict(df) == 1]
df_outlier_robust_covariance

# df_outlier_robust_covariance.isnull().sum(axis=0)
fig, ax = plt.subplots(1, 1, figsize=(20, 20))
box5 = df_outlier_robust_covariance.drop(['start_instant', 'end_instant', 'baseline_value_expert', 'baseline_value_SisPorto', 'Output'], axis=1)
box5.boxplot(ax=ax, rot=90, showfliers=True)
plt.tight_layout()
plt.show()

"""## Feature Engineering"""

preprocessed_df = df_outlier_robust_covariance.copy(deep=True)
preprocessed_df.describe()

"""### Observing Corelation for feature selection"""

plt.figure(figsize=(30, 15))
sns.heatmap(preprocessed_df.corr(), annot=True)

plt.show()

# Cols to be removed:
col_removed = ['repetitive_decelerations', 'severe_decelerations', 'prolongued_decelerations', 'start_instant', 'end_instant', 'histogram_mode', 'histogram_tendency', 'calm_vigilance', 'active_vigilance', 'baseline_value_expert']
preprocessed_df = preprocessed_df.drop(col_removed, axis=1)
preprocessed_df.head()

"""## Exploring and Visualising the Data

*  Histograms, Scatter Plots, Pair Plots, Bar Plots, Distribution Plots

#### Pairplots
"""

# # Creating pairplots for the whole preprocessed dataset
# import seaborn as sns
# sns.pairplot(preprocessed_df, hue='Output')
# plt.show()

# Creating pairplots
import seaborn as sns
pairplot_df1 = preprocessed_df.iloc[:, 0:9]
pairplot_df1['Output'] = preprocessed_df['Output']
sns.pairplot(pairplot_df1, hue='Output')
plt.show()

# Creating pairplots
import seaborn as sns
pairplot_df2 = preprocessed_df.iloc[:, 9:18]
sns.set_palette("bright")
pairplot_df2['Output'] = preprocessed_df['Output']
sns.pairplot(pairplot_df2, hue='Output')
plt.show()

# Creating pairplots
import seaborn as sns
pairplot_df3 = preprocessed_df.iloc[:, 18:26]
pairplot_df3['Output'] = preprocessed_df['Output']
sns.pairplot(pairplot_df3, hue='Output')
plt.show()

"""#### Scatter Plots"""

# Creating Scatter Plots
n1 = 5
n2 = 5
fig, ax = plt.subplots(n1, n2, figsize=(20,20))
col = 0
for i in range(n1):
  for j in range(n2):
    ax[i][j].scatter(y=preprocessed_df.iloc[:, col],x=preprocessed_df['Output'],color='red')
    ax[i][j].set_ylabel(preprocessed_df.columns[col])
    ax[i][j].set_xlabel('Output')
    col+=1

plt.tight_layout()
plt.show()

"""### Distribution Plots

#### each attribute
"""

preprocessed_df.hist(figsize=(17,17), bins=20)
plt.tight_layout()
plt.show()

"""#### output class imbalance"""

plt.figure(figsize=(10, 5))
plt.hist(preprocessed_df['Output'])
plt.xlabel('Output')
plt.ylabel('Frequency')
plt.title('Output Frequency')
plt.show()

plt.figure(figsize=(10, 5))
plt.pie(preprocessed_df['Output'].value_counts(), labels=['Normal', 'Suspect', 'Pathological'], autopct='%1.1f%%')
plt.title('Output Frequency')
plt.show()

"""#### Creating distribution plots"""

for i in range(len(preprocessed_df.columns)):
  sns.displot(preprocessed_df.iloc[:, i], kde=True)
  plt.xticks(rotation=90)

plt.tight_layout()
plt.show()

"""## **Resampling**

### **UnderSampling**
"""

from imblearn.under_sampling import NearMiss

def under_sample(df):
    nm = NearMiss()

    X = df.iloc[:, :-1]
    y = df.iloc[:, -1]

    X, y = nm.fit_resample(X, y)
    return x,y

x,y = under_sample(preprocessed_df)
y = pd.Series(y)
# values in y after resampling
pd.Series(y).value_counts()

plt.figure(figsize=(5, 5))
plt.pie(y.value_counts(), labels=y.unique(), autopct='%1.1f%%', shadow=True, startangle=90)
plt.show()

"""### *OverSampling*"""

# Resampling the dataset using SMOTE

from imblearn.over_sampling import SMOTE

def over_sample(preprocessed_df):
    x = preprocessed_df.iloc[:, :-1]
    y = preprocessed_df.iloc[:, -1]
    y = y.astype(np.uint8)
    y = [i-1 for i in y]
    smote = SMOTE()

    x, y = smote.fit_resample(x, y)
    return x,y

x,y = over_sample(preprocessed_df)
y = pd.Series(y)
pd.Series(y).value_counts()

plt.figure(figsize=(5, 5))
plt.pie(y.value_counts(), labels=y.unique(), autopct='%1.1f%%', shadow=True, startangle=90)
plt.show()

"""# Basic ML Models

## Train:Test Split & Training
"""

# Implementing ML Models
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler


def get_train_test_data(df, if_pca=True, n_components=10, test_size=0.2):
    X, y = over_sample(df)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

    # Applying PCA

    if if_pca:
        pca = PCA(n_components=n_components)
        pca.fit(X_train)
        X_train = pca.transform(X_train)
        X_test = pca.transform(X_test)

    # Applying Standard Scaler
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)

    return X_train, X_test, y_train, y_test

"""#### Implementing Logistic Regression, SVM, and KNN models"""

# 3 Class Classification

# Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, classification_report

def run_model(model, X_train, y_train, X_test, y_test):
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)

    print('Train Score:', train_score)
    print('Test Score:', test_score)
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    return train_score, test_score

def basic_ML_models(df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=True, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    print('\t\t\t\t\tLogistic Regression')
    model = LogisticRegression(max_iter=max_iters, C=lr, solver='liblinear')
    model.fit(X_train, y_train)
    model_train_scores['Logistic Regression'] , model_test_scores['Logistic Regression'] = run_model(model, X_train, y_train, X_test, y_test)

    # Naive-Bayes
    print('\t\t\t\t\tGaussian Naive-Bayes Classifier')
    model = GaussianNB()
    model.fit(X_train, y_train)
    model_train_scores['Naive Bayes'], model_test_scores['Naive Bayes'] = run_model(model, X_train, y_train, X_test, y_test)

    # KNN

    print('\t\t\t\t\tKNN')

    model = KNeighborsClassifier()
    model.fit(X_train, y_train)
    model_train_scores['KNN'], model_test_scores['KNN'] = run_model(model, X_train, y_train, X_test, y_test)

    # SVM

    print('\t\t\t\t\tSVM')

    model = SVC()
    model.fit(X_train, y_train)
    model_train_scores['SVM'], model_test_scores['SVM'] = run_model(model, X_train, y_train, X_test, y_test)

    return model_train_scores, model_test_scores

# using k-fold stratified cross validation

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score

def run_model(model, X_train, y_train, X_test, y_test):
    cv_score = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')

    print('Train Score:', cv_score.mean())
    print('Test Score:', model.score(X_test, y_test))
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    return cv_score.mean(), model.score(X_test, y_test)

def basic_ML_models_k_fold(df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=False, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # Logistic Regression
    lr = LogisticRegression(max_iter=max_iters, C=lr, solver='liblinear')
    print('\t\t\t\tLogistic Regression')
    model_train_scores['Logistic Regression'], model_test_scores['Logistic Regression'] = run_model(lr, X_train, y_train, X_test, y_test)

    # KNN
    knn = KNeighborsClassifier()
    print('\t\t\t\tKNN')
    model_train_scores['KNN'], model_test_scores['KNN'] = run_model(knn, X_train, y_train, X_test, y_test)

    # SVM
    model = SVC()
    print('\t\t\t\tSVM')
    model_train_scores['SVM'], model_test_scores['SVM'] = run_model(model, X_train, y_train, X_test, y_test)

    return model_train_scores, model_test_scores

"""## Running the models

### Without PCA

Overfitting happens
"""

model_train_scores, model_test_scores = basic_ML_models(preprocessed_df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=False, n_components=10)

"""### With PCA
   Reduces Overfitting
"""

model_train_scores, model_test_scores = basic_ML_models(preprocessed_df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=True, n_components=5)

"""### K-Fold Cross Validation"""

model_train_scores, model_test_scores = basic_ML_models_k_fold(preprocessed_df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=True, n_components=5)

"""## Decision Trees"""

# Decision Tree

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

def decision_tree(df, test_size=0.2, tune_parameters=False, if_pca=False, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # Decision Tree
    model = DecisionTreeClassifier()
    model.fit(X_train, y_train)
    model_train_scores['Decision Tree'] = model.score(X_train, y_train)
    model_test_scores['Decision Tree'] = model.score(X_test, y_test)

    print('Decision Tree')
    print('Train Score:', model_train_scores['Decision Tree'])
    print('Test Score:', model_test_scores['Decision Tree'])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    # Decision Tree with Pruning

    if tune_parameters:
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [2, 3, 4, 5, 6, 7, 8],
            'min_samples_split': [2, 3, 4, 5, 6, 7, 8],
            'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8]
        }

        model = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
        model.fit(X_train, y_train)
        model_train_scores['Decision Tree with Pruning'] = model.score(X_train, y_train)
        model_test_scores['Decision Tree with Pruning'] = model.score(X_test, y_test)

        print('Decision Tree with Pruning')
        print('Train Score:', model_train_scores['Decision Tree with Pruning'])
        print('Test Score:', model_test_scores['Decision Tree with Pruning'])
        print('Best Parameters:', model.best_params_)
        print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
        print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
        print('--------------------------------------------------\n')

    return model_train_scores, model_test_scores

# Calling decision_tree

model_train_scores, model_test_scores = decision_tree(preprocessed_df, test_size=0.25, if_pca=True, n_components=10)

# Implementing decision tree with pre-pruning and post-pruning

from sklearn.tree import DecisionTreeClassifier

def decision_tree_pruning(df, test_size=0.2, if_pca=False, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # Decision Tree with Pre-Pruning

    model = DecisionTreeClassifier(max_depth=3, min_samples_split=2, min_samples_leaf=1)
    model.fit(X_train, y_train)
    model_train_scores['Decision Tree with Pre-Pruning'] = model.score(X_train, y_train)
    model_test_scores['Decision Tree with Pre-Pruning'] = model.score(X_test, y_test)

    print('Decision Tree with Pre-Pruning')
    print('Train Score:', model_train_scores['Decision Tree with Pre-Pruning'])
    print('Test Score:', model_test_scores['Decision Tree with Pre-Pruning'])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    # Decision Tree with Post-Pruning

    model = DecisionTreeClassifier()
    path = model.cost_complexity_pruning_path(X_train, y_train)
    ccp_alphas, impurities = path.ccp_alphas, path.impurities
    models = []
    for ccp_alpha in ccp_alphas:
        model = DecisionTreeClassifier(ccp_alpha=ccp_alpha)
        model.fit(X_train, y_train)
        models.append(model)
    train_scores = [model.score(X_train, y_train) for model in models]
    test_scores = [model.score(X_test, y_test) for model in models]

    model = DecisionTreeClassifier(ccp_alpha=ccp_alphas[np.argmax(test_scores)])
    model.fit(X_train, y_train)
    model_train_scores['Decision Tree with Post-Pruning'] = model.score(X_train, y_train)
    model_test_scores['Decision Tree with Post-Pruning'] = model.score(X_test, y_test)

    print('Decision Tree with Post-Pruning')
    print('Train Score:', model_train_scores['Decision Tree with Post-Pruning'])
    print('Test Score:', model_test_scores['Decision Tree with Post-Pruning'])
    print('Best Alpha:', ccp_alphas[np.argmax(test_scores)])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    return model_train_scores, model_test_scores

# Calling decision_tree_pruning

model_train_scores, model_test_scores = decision_tree_pruning(preprocessed_df, test_size=0.2, if_pca=False, n_components=10)

# Calling decision_tree_pruning

model_train_scores, model_test_scores = decision_tree_pruning(preprocessed_df, test_size=0.2, if_pca=True, n_components=10)

"""### **Observations**

* We can observe, that with 27 features, the data overfits the model and gives an
accuracy of ~99% even with a very low training set.
* Once we implement PCA, and select the most deciding components/features, it helps us in reducing the overfitting.
* Here, we are also using regularization, indicated by *solver = 'liblinear'*, which is L2, L1 regularization.
* Thus, we can observe that using these techniques, we successfully reduce the model overfitting and make it closer to real-world prediction scenario.

#### Using AutoML to verify our findings
"""

!pip install tpot

from tpot import TPOTClassifier
from sklearn.model_selection import RepeatedStratifiedKFold

train_X, test_X, train_y, test_y = get_train_test_data(preprocessed_df, if_pca=True, n_components=10)

# define model evaluation procedure
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# define search
model = TPOTClassifier(generations=5, population_size=50, cv=5, scoring='accuracy', verbosity=2, random_state=1, n_jobs=-1)
# perform the search
model.fit(train_X, train_y)
# export the best model
model.export('tpot_best_model.py')

y_pred_tpot = model.predict(test_X)

print('TPOT')
print('Train Score:', model.score(train_X, train_y))
print('Test Score:', model.score(test_X, test_y))
print('Confusion Matrix:', confusion_matrix(test_y, y_pred_tpot))
print('Classification Report:', classification_report(test_y, y_pred_tpot))

"""# Advanced ML Models

## Random Forests
"""

# Implementing Random Forest

from sklearn.ensemble import RandomForestClassifier

def random_forest(df, test_size=0.2, tune_parameters=False, if_pca=True, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # Random Forest

    model = RandomForestClassifier(criterion = 'gini', max_depth = 5)
    model.fit(X_train, y_train)
    model_train_scores['Random Forest'] = model.score(X_train, y_train)
    model_test_scores['Random Forest'] = model.score(X_test, y_test)

    print('Random Forest')
    print('Train Score:', model_train_scores['Random Forest'])
    print('Test Score:', model_test_scores['Random Forest'])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    # Random Forest with Pruning
    if tune_parameters:
        param_grid = {
            'n_estimators': [10, 20, 30,50, 70, 80],
            'criterion': ['gini', 'entropy'],
            'max_depth': [4, 5, 6],
            'min_samples_split': [6, 7, 8],
            'min_samples_leaf': [1, 2, 3, 4, ]
        }

        model = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
        model.fit(X_train, y_train)
        model_train_scores['Random Forest GS'] = model.score(X_train, y_train)
        model_test_scores['Random Forest GS'] = model.score(X_test, y_test)

        print('Hyperparameter Tuning on Random Forest (Pruning)')
        print('Train Score:', model_train_scores['Random Forest GS'])
        print('Test Score:', model_test_scores['Random Forest GS'])
        print('Best Parameters:', model.best_params_)
        print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
        print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))

    return model_train_scores, model_test_scores

# Calling random_forest
model_train_scores, model_test_scores = random_forest(preprocessed_df, test_size=0.2, if_pca=True, n_components=10)

"""## XGBoost"""

# Implementing XGBoost

from xgboost import XGBClassifier

def xgboost(df, test_size=0.2, tune_parameters=False, if_pca=True, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # XGBoost

    model = XGBClassifier(max_depth=2, learning_rate=0.1, min_child_weight=4, gamma=0.1)
    model.fit(X_train, y_train)
    model_train_scores['XGBoost'] = model.score(X_train, y_train)
    model_test_scores['XGBoost'] = model.score(X_test, y_test)

    print('XGBoost')
    print('Train Score:', model_train_scores['XGBoost'])
    print('Test Score:', model_test_scores['XGBoost'])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    if tune_parameters:
        param_grid = {
            'n_estimators': [20, 30, 50, 70, 80],
            'max_depth': [4, 5, 6],
            'learning_rate': [0.1, 0.01, 0.001],
            'min_child_weight': [4, 5, 6, 7, 8],
            'gamma': [0, 0.1, 0.2, 0.001]
        }

        model = GridSearchCV(XGBClassifier(), param_grid, cv=5)
        model.fit(X_train, y_train)
        model_train_scores['XGBoost_GS'] = model.score(X_train, y_train)
        model_test_scores['XGBoost_GS'] = model.score(X_test, y_test)

        print('Hyperparameter Tuning of XGBoost')
        print('Train Score:', model_train_scores['XGBoost_GS'])
        print('Test Score:', model_test_scores['XGBoost_GS'])
        print('Best Parameters:', model.best_params_)
        print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
        print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
        print('--------------------------------------------------\n')

    return model_train_scores, model_test_scores

# Calling xgboost
model_train_scores, model_test_scores = xgboost(preprocessed_df, test_size=0.2)

"""# Deep Learning Models

## Artificial Neural Networks (ANN)
"""

# Implementing ANN using MLPClassifier

from sklearn.neural_network import MLPClassifier

def ann(df, hidden_layers, test_size=0.2, if_pca=True, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # ANN

    model = MLPClassifier(hidden_layer_sizes=hidden_layers, max_iter=1000)
    model.fit(X_train, y_train)
    model_train_scores['ANN'] = model.score(X_train, y_train)
    model_test_scores['ANN'] = model.score(X_test, y_test)

    print('ANN')
    print('Train Score:', model_train_scores['ANN'])
    print('Test Score:', model_test_scores['ANN'])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    return model_train_scores, model_test_scores, model

# Calling ann
model_train_scores, model_test_scores, model = ann(preprocessed_df, hidden_layers=(512, 256, 128, 64), test_size=0.2, if_pca=True, n_components=10)

"""# 10-Class Classification Problem

## Data Preprocessing
"""

# {"A": "calm_sleep",
# "B": "REM_sleep",
# "C": "calm_vigilance",
# "D": "active_vigilance",
# "E": "E",
# "SH": "shift_pattern",
# "AD": "accel/decel_pattern_stress",
# "DE": "decelerative_pattern_vagal",
# "LD": "large_decelerative_pattern",
# "FS": "flat_sinusoidal_pattern",
# "SUSP": "suspect_pattern",
# "CLASS": "class_code",
# "NSP": "Output"}

cols = preprocessed_df.columns.tolist()
index = preprocessed_df.columns.get_loc('class_code')
cols[-1], cols[index] = cols[index], cols[-1]
preprocessed_df = preprocessed_df[cols]
cols = preprocessed_df.columns.tolist()

plt.figure(figsize=(10, 5))
plt.pie(preprocessed_df['class_code'].value_counts(), labels=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], autopct='%1.1f%%')
plt.title('Output Frequency')
plt.show()

# Resampling the dataset using SMOTE

from imblearn.over_sampling import SMOTE

def over_sample(preprocessed_df):
    x = preprocessed_df.iloc[:, :-1]
    y = preprocessed_df.iloc[:, -1]
    y = y.astype(np.uint8)
    y = [i-1 for i in y]
    return x,y

"""## Basic ML Models

### Without_PCA
"""

model_train_scores, model_test_scores = basic_ML_models(preprocessed_df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=False, n_components=10)

"""### With_PCA"""

model_train_scores, model_test_scores = basic_ML_models(preprocessed_df, test_size=0.2, max_iters= 1000, lr = 0.1, if_pca=True, n_components=10)

"""## Decision Tree"""

# with pca
model_train_scores, model_test_scores = decision_tree(preprocessed_df, test_size=0.25, if_pca=True, n_components=10)

# with pruning without pca
model_train_scores, model_test_scores = decision_tree_pruning(preprocessed_df, test_size=0.2, if_pca=False, n_components=10)

# with pruning and pca
model_train_scores, model_test_scores = decision_tree_pruning(preprocessed_df, test_size=0.2, if_pca=True, n_components=10)

"""## Random Forest"""

model_train_scores, model_test_scores = random_forest(preprocessed_df, test_size=0.2, if_pca=True, n_components=10)

"""## XGBoost"""

model_train_scores, model_test_scores = xgboost(preprocessed_df, test_size=0.2)

"""## CATBoost"""

!pip install catboost

# Implement CATBoost

from catboost import CatBoostClassifier

def catboost(df, test_size=0.2, if_pca=True, n_components=10):
    X_train, X_test, y_train, y_test = get_train_test_data(df, if_pca, n_components, test_size)
    model_train_scores = dict()
    model_test_scores = dict()

    # CATBoost

    model = CatBoostClassifier(verbose=100, max_depth = 3)
    model.fit(X_train, y_train)
    model_train_scores['CATBoost'] = model.score(X_train, y_train)
    model_test_scores['CATBoost'] = model.score(X_test, y_test)

    print('CATBoost')
    print('Train Score:', model_train_scores['CATBoost'])
    print('Test Score:', model_test_scores['CATBoost'])
    print('Confusion Matrix:\n', confusion_matrix(y_test, model.predict(X_test)))
    print('Classification Report:\n', classification_report(y_test, model.predict(X_test)))
    print('--------------------------------------------------\n')

    return model_train_scores, model_test_scores, model

model_train_scores, model_test_scores, model = catboost(preprocessed_df, test_size=0.2, if_pca=True, n_components=10)

image = model.plot_tree(tree_idx = 0)
image.render()

image

"""### Training Loss"""

plt.figure(figsize=(10, 5))
plt.plot(model.evals_result_['learn']['MultiClass'], label='train')
plt.legend()
plt.show()

"""## Artificial Neural Network"""

model_train_scores, model_test_scores, model = ann(preprocessed_df, hidden_layers=(512, 256, 128, 64), test_size=0.2, if_pca=True, n_components=10)

"""### Loss Curve"""

plt.plot(model.loss_curve_)
plt.title('Loss Curve')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.show()